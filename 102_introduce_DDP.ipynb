{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkmEhdDFpR9DfXWYJI1muM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaobin675/Path_in_ML_model_training/blob/main/102_introduce_DDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQfQnZfa0KwN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "'''\n",
        "data_factory.py\n",
        "a modular architecture. one module handles the data factory,\n",
        "another the model's brain, and a third coordinates the distributed workers.\n",
        "'''\n",
        "\n",
        "def get_data_loaders(dataset, batch_size, world_size, rank):\n",
        "    sampler = DistributedSampler(\n",
        "        dataset,\n",
        "        num_replicas=world_size,\n",
        "        rank=rank,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=8,       # High number for fast augmentation\n",
        "        pin_memory=True,     # Necessary for fast GPU transfer\n",
        "        prefetch_factor=2    # Pre-loads next batches while GPU works\n",
        "    )\n",
        "    return loader, sampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "\n",
        "class XRayDataset(Dataset):\n",
        "    def __init__(self, paths, transform=None):\n",
        "        self.paths = paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image (OpenCV is C++ optimized)\n",
        "        img = cv2.imread(self.paths[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply high-concurrency augmentation\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img)\n",
        "            img = augmented['image']\n",
        "\n",
        "        return img # Returns a Tensor [3, 224, 224]"
      ],
      "metadata": {
        "id": "CZaTIduw7BSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\"\"\"\n",
        "trainer.py\n",
        "Provides a DDPTrainer wrapper that encapsulates PyTorch DistributedDataParallel (DDP)\n",
        "initialization and epoch execution logic for multi-GPU training.\n",
        "\"\"\"\n",
        "class DDPTrainer:\n",
        "    \"\"\"\n",
        "    Wraps a model with DistributedDataParallel (DDP) and manages distributed epoch execution.\n",
        "    Assumes torch.distributed.init_process_group() has been called prior to instantiation.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, gpu_id, lr=1e-4):\n",
        "        self.gpu_id = gpu_id\n",
        "        self.model = DDP(model.to(gpu_id), device_ids=[gpu_id])\n",
        "\n",
        "        # uses AdamW for stability\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=lr)\n",
        "        self.criterion = nn.CosineEmbeddingLoss() # Common for learning embeddings\n",
        "\n",
        "    def train_step(self, images):\n",
        "        '''\n",
        "        Update the model's weights to get smarter.\n",
        "        '''\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = self.model(images)\n",
        "\n",
        "        # we might compare an image to its augmented version.\n",
        "        # Here we just show the mechanical backward pass:\n",
        "        loss = embeddings.sum() # Simplified placeholder for the loss math\n",
        "\n",
        "        loss.backward()         # DDP syncs gradients here\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def save_checkpoint(self, epoch, path):\n",
        "        # Only save on the 'Master' node (Rank 0) to avoid file corruption\n",
        "        if self.gpu_id == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': self.model.module.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            }, f\"{path}/checkpoint_{epoch}.pt\")\n",
        "\n",
        "    def generate_embeddings(self, loader):\n",
        "        '''\n",
        "        Use the already learned weights to describe an image.\n",
        "        '''\n",
        "        self.model.eval()\n",
        "        all_vecs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                # Move augmented images to GPU\n",
        "                batch = batch.to(self.gpu_id, non_blocking=True)\n",
        "\n",
        "                # The 'Embedding' is the output of our model\n",
        "                embeddings = self.model(batch)\n",
        "\n",
        "                # Move back to CPU for storage\n",
        "                all_vecs.append(embeddings.cpu())\n",
        "\n",
        "        return torch.cat(all_vecs)\n"
      ],
      "metadata": {
        "id": "oXCfLhsY0vPy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "#model.py\n",
        "class XRayEncoder(nn.Module):\n",
        "    def __init__(self, model_name='resnet50'):\n",
        "        super().__init__()\n",
        "        # Flexible backbone selection\n",
        "        if model_name == 'resnet50':\n",
        "            base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Remove the classification head\n",
        "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return torch.flatten(features, 1) # Returns the 1D Embedding"
      ],
      "metadata": {
        "id": "QuwFso4r2s8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch.distributed as dist\n",
        "from model import XRayEncoder\n",
        "from trainer import DDPTrainer\n",
        "from data_factory import get_data_loaders\n",
        "from augment import XRayAugmenter\n",
        "from data_loader import XRayDataset\n",
        "\n",
        "def main():\n",
        "    # 1. Initialize Distributed Backend\n",
        "    dist.init_process_group(backend=\"nccl\")\n",
        "    gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
        "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    # 2. Prepare Data (Google-scale: thousands of paths)\n",
        "    all_image_paths = glob.glob(\"/path/to/big_data/*.jpg\")\n",
        "    augmenter = XRayAugmenter(img_size=224)\n",
        "    dataset = XRayDataset(all_image_paths, transform=augmenter.train_transform)\n",
        "\n",
        "    loader, sampler = get_data_loaders(\n",
        "        dataset,\n",
        "        batch_size=64,\n",
        "        world_size=world_size,\n",
        "        rank=gpu_id\n",
        "    )\n",
        "\n",
        "    # 3. Initialize Model and Trainer\n",
        "    model = XRayEncoder()\n",
        "    trainer = DDPTrainer(model, gpu_id)\n",
        "\n",
        "    # 4. Training Loop\n",
        "    for epoch in range(10):\n",
        "        sampler.set_epoch(epoch) # Critical for shuffling in DDP\n",
        "        for batch_idx, images in enumerate(loader):\n",
        "            images = images.to(gpu_id, non_blocking=True)\n",
        "            loss = trainer.train_step(images)\n",
        "\n",
        "            if gpu_id == 0 and batch_idx % 10 == 0:\n",
        "                print(f\"Epoch {epoch} | Batch {batch_idx} | Loss: {loss:.4f}\")\n",
        "\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "wGRTXFPD2YJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#config.py\n",
        "class Config:\n",
        "    # üåç Distributed Settings\n",
        "    WORLD_SIZE = torch.cuda.device_count()\n",
        "    BACKEND = \"nccl\"\n",
        "\n",
        "    # üß¨ Hyperparameters\n",
        "    BATCH_SIZE = 64\n",
        "    IMG_SIZE = 224\n",
        "    LEARNING_RATE = 1e-4\n",
        "    EPOCHS = 50\n",
        "\n",
        "    # üìÇ Paths\n",
        "    DATA_DIR = \"./data/xrays/\"\n",
        "    CHECKPOINT_DIR = \"./checkpoints/\""
      ],
      "metadata": {
        "id": "pAKKTHIy2hzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}