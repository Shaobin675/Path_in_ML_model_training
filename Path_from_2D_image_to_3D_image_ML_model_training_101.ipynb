{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa6SOAnHusSCuncPLP3QdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaobin675/Path_in_ML_model_training/blob/main/Path_from_2D_image_to_3D_image_ML_model_training_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jFnD80NNk11z"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "'''\n",
        "augment.py\n",
        "By putting them in one pipeline, allow the model to learn complex combinations.\n",
        "In the real world, an X-ray might be both dark and noisy. If you only trained them separately,\n",
        "the model might get confused when it sees both issues at once.\n",
        "'''\n",
        "class XRayAugmenter:\n",
        "    def __init__(self, img_size=224):\n",
        "        # We define a pipeline\n",
        "        self.train_transform = A.Compose([\n",
        "            A.Resize(img_size, img_size),\n",
        "            # Realistic variations\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            # Standardize for the ML model\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "    def apply(self, image_path):\n",
        "        # Load using OpenCV (C++ backend)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return self.train_transform(image=image)['image']\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "#feature_extractor.py or model\n",
        "class XRayEncoder(nn.Module):\n",
        "    def __init__(self, model_name='resnet50'):\n",
        "        super(XRayEncoder, self).__init__()\n",
        "        # Load pre-trained backbone\n",
        "        base_model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Remove the classification head (last layer)\n",
        "        # ResNet50's last layer is named 'fc'\n",
        "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
        "\n",
        "        # Freeze parameters (Optional: either save compute or not)\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is the augmented image tensor from our pipeline\n",
        "        embedding = self.backbone(x)\n",
        "        # Flatten from (1, 2048, 1, 1) to (1, 2048)\n",
        "        return torch.flatten(embedding, 1)\n",
        "import os\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#data_loader.py\n",
        "class XRayDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load one image at a time\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            # Applying your specific augmentation class logic\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        return image\n",
        "\n",
        "# Usage for large-scale:\n",
        "# loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "\n",
        "def run_production_inference():\n",
        "    # A. Setup Device (The \"Engine\")\n",
        "    # This detects NVIDIA GPU (cuda), Apple Silicon (mps), or CPU\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"Running on: {device}\")\n",
        "\n",
        "    # B. Initialize System Components\n",
        "    augmenter = XRayAugmenter(img_size=224)\n",
        "    model = XRayEncoder().to(device) # Move entire model to GPU\n",
        "    model.eval()\n",
        "\n",
        "    # C. Data Loading\n",
        "    image_list = glob.glob(\"path/to/xrays/*.jpg\") # Thousands of images\n",
        "    dataset = XRayDataset(image_list, transform=augmenter.train_transform)\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=64,       # Process 64 images at once\n",
        "        num_workers=4,        # 4 CPU processes fetching images (Beats the GIL)\n",
        "        pin_memory=True       # Faster transfer from RAM to GPU\n",
        "    )\n",
        "\n",
        "    # D. Inference Loop\n",
        "    all_embeddings = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient math to save memory\n",
        "        for batch in loader:\n",
        "            # Move data batch to GPU\n",
        "            batch = batch.to(device, non_blocking=True)\n",
        "\n",
        "            # Forward pass on GPU\n",
        "            embeddings = model(batch)\n",
        "\n",
        "            # Move back to CPU for storage/analysis\n",
        "            all_embeddings.append(embeddings.cpu())\n",
        "\n",
        "    # Stack all batches into one big matrix\n",
        "    final_database = torch.cat(all_embeddings, dim=0)\n",
        "    print(f\"âœ… Generated {final_database.shape[0]} embeddings.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_production_inference()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTmuutxbow0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "So-BqSGdqZrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}