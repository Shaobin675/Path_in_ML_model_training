{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp8O2swavs5h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "#feature_extractor.py or model\n",
        "class XRayEncoder(nn.Module):\n",
        "    def __init__(self, model_name='resnet50'):\n",
        "        super(XRayEncoder, self).__init__()\n",
        "        # Load pre-trained backbone\n",
        "        base_model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Remove the classification head (last layer)\n",
        "        # ResNet50's last layer is named 'fc'\n",
        "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
        "\n",
        "        # Freeze parameters (Optional: either save compute or not)\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is the augmented image tensor from our pipeline\n",
        "        embedding = self.backbone(x)\n",
        "        # Flatten from (1, 2048, 1, 1) to (1, 2048)\n",
        "        return torch.flatten(embedding, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rry3PjcnvwX_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#data_loader.py\n",
        "class XRayDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load one image at a time\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            # Applying your specific augmentation class logic\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        return image\n",
        "\n",
        "# Usage for large-scale:\n",
        "# loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhP1RAr8vyj1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "\n",
        "def run_production_inference():\n",
        "    # A. Setup Device (The \"Engine\")\n",
        "    # This detects NVIDIA GPU (cuda), Apple Silicon (mps), or CPU\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"Running on: {device}\")\n",
        "\n",
        "    # B. Initialize System Components\n",
        "    augmenter = XRayAugmenter(img_size=224)\n",
        "    model = XRayEncoder().to(device) # Move entire model to GPU\n",
        "    model.eval()\n",
        "\n",
        "    # C. Data Loading\n",
        "    image_list = glob.glob(\"path/to/xrays/*.jpg\") # Thousands of images\n",
        "    dataset = XRayDataset(image_list, transform=augmenter.train_transform)\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=64,       # Process 64 images at once\n",
        "        num_workers=4,        # 4 CPU processes fetching images (Beats the GIL)\n",
        "        pin_memory=True       # Faster transfer from RAM to GPU\n",
        "    )\n",
        "\n",
        "    # D. Inference Loop\n",
        "    all_embeddings = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient math to save memory\n",
        "        for batch in loader:\n",
        "            # Move data batch to GPU\n",
        "            batch = batch.to(device, non_blocking=True)\n",
        "\n",
        "            # Forward pass on GPU\n",
        "            embeddings = model(batch)\n",
        "\n",
        "            # Move back to CPU for storage/analysis\n",
        "            all_embeddings.append(embeddings.cpu())\n",
        "\n",
        "    # Stack all batches into one big matrix\n",
        "    final_database = torch.cat(all_embeddings, dim=0)\n",
        "    print(f\"Generated {final_database.shape[0]} embeddings.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_production_inference()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOKsrVDO38H78EyNjKjHvNJ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
